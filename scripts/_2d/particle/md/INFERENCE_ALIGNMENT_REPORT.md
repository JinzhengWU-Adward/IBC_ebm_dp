# Particle æ¨ç†é…ç½®å¯¹é½æ£€æŸ¥æŠ¥å‘Š

## æ£€æŸ¥ç›®æ ‡
å¯¹æ¯” `particle_test.py` ä¸ IBC å®˜æ–¹çš„ `run_mlp_ebm_langevin.sh` é…ç½®ï¼ŒéªŒè¯æ¨ç†æ—¶çš„æ‰€æœ‰è®¾ç½®æ˜¯å¦æ­£ç¡®ã€‚

---

## 1. IBC å®˜æ–¹æ¨ç†é…ç½®

### 1.1 Langevin é‡‡æ ·é…ç½® (`mlp_ebm_langevin.gin`)

```gin
# ç¬¬ 31-39 è¡Œï¼šæ¨ç†é…ç½®
IbcPolicy.num_action_samples = 512  # æ¯æ­¥é‡‡æ · 512 ä¸ªå€™é€‰åŠ¨ä½œ
IbcPolicy.use_dfo = False           # ä¸ä½¿ç”¨ DFO
IbcPolicy.use_langevin = True       # ä½¿ç”¨ Langevin MCMC
IbcPolicy.optimize_again = False    # ä¸è¿›è¡ŒäºŒæ¬¡ä¼˜åŒ–

# ç¬¬ 59 è¡Œï¼šLangevin è¿­ä»£æ¬¡æ•°
langevin_actions_given_obs.num_iterations = 100
```

### 1.2 Langevin é‡‡æ ·å™¨é»˜è®¤å‚æ•° (`ibc/ibc/agents/mcmc.py`)

```python
# ç¬¬ 332-355 è¡Œ
@gin.configurable
def langevin_actions_given_obs(
    energy_network,
    observations,
    action_samples,
    policy_state,
    min_actions,
    max_actions,
    num_action_samples,
    num_iterations=25,           # é»˜è®¤ 25ï¼Œä½† gin é…ç½®ä¸º 100
    training=False,
    tfa_step_type=(),
    sampler_stepsize_init=1e-1,  # åˆå§‹æ­¥é•¿
    sampler_stepsize_decay=0.8,
    noise_scale=1.0,             # å™ªå£°å°ºåº¦
    grad_clip=None,
    delta_action_clip=0.1,
    stop_chain_grad=True,
    apply_exp=False,
    use_polynomial_rate=True,    # ä½¿ç”¨å¤šé¡¹å¼è¡°å‡
    sampler_stepsize_final=1e-5, # æœ€ç»ˆæ­¥é•¿
    sampler_stepsize_power=2.0,  # è¡°å‡å¹‚æ¬¡
    return_chain=False,
    grad_norm_type='inf',
    late_fusion=False
):
```

**å…³é”®å‚æ•°ï¼š**
- `num_iterations`: 100ï¼ˆParticle é…ç½®ï¼‰
- `sampler_stepsize_init`: 0.1
- `sampler_stepsize_final`: 1e-5
- `sampler_stepsize_power`: 2.0
- `use_polynomial_rate`: True
- `noise_scale`: 1.0

### 1.3 åŠ¨ä½œé€‰æ‹©ç­–ç•¥ (`ibc/ibc/agents/ibc_policy.py`)

```python
# ç¬¬ 313-328 è¡Œï¼šæ¨ç†æ—¶çš„åŠ¨ä½œé€‰æ‹©
probs = mcmc.get_probabilities(
    self._actor_network,
    batch_size,
    self._num_action_samples,
    maybe_tiled_obs,
    action_samples,
    training=False
)

# Make a distribution for sampling.
distribution = MappedCategorical(
    probs=probs, mapped_values=action_samples)
return policy_step.PolicyStep(distribution, policy_state)
```

**`get_probabilities` å®ç° (`mcmc.py` ç¬¬ 428-441 è¡Œ)ï¼š**

```python
def get_probabilities(energy_network,
                      batch_size,
                      num_action_samples,
                      observations,
                      actions,
                      training,
                      temperature=1.0):
  """Get probabilities to post-process Langevin results."""
  net_logits, _ = energy_network((observations, actions), training=training)
  net_logits = tf.reshape(net_logits, (batch_size, num_action_samples))
  probs = tf.nn.softmax(net_logits / temperature, axis=1)  # â† softmax(-energy)
  probs = tf.reshape(probs, (-1,))
  return probs
```

**åŠ¨ä½œé€‰æ‹© (`ibc/ibc/agents/ibc_agent.py` ç¬¬ 120 è¡Œ)ï¼š**

```python
policy = greedy_policy.GreedyPolicy(collect_policy)
```

**å…³é”®æµç¨‹ï¼š**
1. Langevin é‡‡æ ·ç”Ÿæˆ 512 ä¸ªå€™é€‰åŠ¨ä½œ
2. è®¡ç®—æ¯ä¸ªå€™é€‰çš„èƒ½é‡ E(obs, action)
3. é€šè¿‡ softmax(E / temperature) è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆæ³¨æ„ï¼šIBC ç½‘ç»œè¾“å‡ºçš„æ˜¯ logitsï¼Œå³è´Ÿèƒ½é‡ï¼‰
4. ä½¿ç”¨ GreedyPolicy é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œï¼ˆ`distribution.mode()`ï¼‰

---

## 2. `particle_test.py` æ¨ç†å®ç°æ£€æŸ¥

### 2.1 ULA é‡‡æ ·å™¨é…ç½®ï¼ˆç¬¬ 820-831 è¡Œï¼‰

```python
action_bounds = np.array([[-1.0, -1.0], [1.0, 1.0]])  # å½’ä¸€åŒ–ç©ºé—´
ula_sampler = ULASampler(
    bounds=action_bounds,
    step_size=0.1,              # sampler_stepsize_init
    num_steps=100,              # num_iterations
    noise_scale=1.0,            # noise_scale
    step_size_final=1e-5,       # sampler_stepsize_final
    step_size_power=2.0,        # sampler_stepsize_power
    device=device
)
```

**å¯¹æ¯”ç»“æœï¼š**
| å‚æ•° | IBC é…ç½® | particle_test.py | ç»“æœ |
|------|----------|------------------|------|
| step_size (åˆå§‹) | 0.1 | 0.1 | âœ… |
| num_steps (è¿­ä»£æ¬¡æ•°) | 100 | 100 | âœ… |
| noise_scale | 1.0 | 1.0 | âœ… |
| step_size_final | 1e-5 | 1e-5 | âœ… |
| step_size_power | 2.0 | 2.0 | âœ… |
| use_polynomial_rate | True | Trueï¼ˆéšå¼ï¼‰ | âœ… |

### 2.2 é‡‡æ ·æ•°é‡ï¼ˆç¬¬ 880 è¡Œï¼‰

```python
pred_trajectory_norm, intermediate_states = infer_trajectory(
    model, obs_seq_tensor, ula_sampler,
    max_steps=min(50, len(true_positions)),
    num_action_samples=512,  # â† åŒ¹é… IBC
    temperature=1.0,
    device=device,
    return_intermediate=True
)
```

**å¯¹æ¯”ç»“æœï¼š**
| å‚æ•° | IBC é…ç½® | particle_test.py | ç»“æœ |
|------|----------|------------------|------|
| num_action_samples | 512 | 512 | âœ… |
| temperature | 1.0ï¼ˆé»˜è®¤ï¼‰ | 1.0 | âœ… |

### 2.3 åŠ¨ä½œé€‰æ‹©ç­–ç•¥ï¼ˆç¬¬ 192-199 è¡Œï¼‰

```python
# ä½¿ç”¨æ¦‚ç‡åˆ†å¸ƒé€‰æ‹©åŠ¨ä½œï¼ˆåŒ¹é… IBC çš„ GreedyPolicy.mode()ï¼‰
# IBC ä½¿ç”¨ GreedyPolicyï¼Œå®ƒä¼šè°ƒç”¨ distribution.mode()ï¼Œç­‰ä»·äº argmax
logits = -energies / temperature  # (1, num_action_samples)
probs = F.softmax(logits, dim=1)  # (1, num_action_samples)

# é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œï¼ˆåŒ¹é… GreedyPolicy çš„è¡Œä¸ºï¼‰
sampled_idx = probs.argmax(dim=1).item()
next_action = candidates[0, sampled_idx].detach().cpu().numpy()  # (2,)
```

**å¯¹æ¯”åˆ†æï¼š**

**IBC çš„å®ç°ï¼š**
```python
# mcmc.py get_probabilities
net_logits = energy_network(obs, actions)  # ç½‘ç»œè¾“å‡º logits
probs = tf.nn.softmax(net_logits / temperature, axis=1)

# ibc_policy.py
distribution = MappedCategorical(probs=probs, mapped_values=action_samples)

# ibc_agent.py
policy = greedy_policy.GreedyPolicy(collect_policy)  # é€‰æ‹© mode()
```

**particle_test.py çš„å®ç°ï¼š**
```python
energies = model(obs_seq, candidates)  # æ¨¡å‹è¾“å‡ºèƒ½é‡å€¼
logits = -energies / temperature       # è½¬æ¢ä¸º logitsï¼ˆè´Ÿèƒ½é‡ï¼‰
probs = F.softmax(logits, dim=1)       # softmax
selected_action = candidates[probs.argmax()]  # é€‰æ‹©æœ€å¤§æ¦‚ç‡
```

**æ£€æŸ¥ç»“æœï¼šâœ… æ­£ç¡®**

**å…³é”®ç‚¹ï¼š**
1. IBC ç½‘ç»œè¾“å‡ºçš„æ˜¯ **logits**ï¼ˆåœ¨ EBM ä¸­ç­‰ä»·äºè´Ÿèƒ½é‡ï¼‰
2. particle_test.py çš„ SequenceEBM è¾“å‡ºçš„æ˜¯ **èƒ½é‡å€¼**
3. å› æ­¤éœ€è¦å–è´Ÿå·ï¼š`logits = -energies`
4. ä¸¤è€…éƒ½ä½¿ç”¨ softmax(logits / temperature) è®¡ç®—æ¦‚ç‡
5. ä¸¤è€…éƒ½é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œï¼ˆargmax / mode()ï¼‰

### 2.4 è§‚æµ‹åºåˆ—æ„å»ºï¼ˆç¬¬ 853-874 è¡Œï¼‰

```python
# ä» episode æ•°æ®ç›´æ¥æ„å»ºåˆå§‹è§‚æµ‹åºåˆ—ï¼Œç¡®ä¿åˆå§‹é€Ÿåº¦ä¸º 0
initial_pos = episode_data['start_position']  # åŸå§‹ç©ºé—´ [0, 1]
initial_vel = np.zeros(2, dtype=np.float32)  # åˆå§‹é€Ÿåº¦ä¸º 0ï¼ˆåŒ¹é… IBCï¼‰
first_goal = episode_data['first_goal']       # åŸå§‹ç©ºé—´
second_goal = episode_data['second_goal']     # åŸå§‹ç©ºé—´

# æ„å»ºåˆå§‹è§‚æµ‹ï¼ˆåŸå§‹ç©ºé—´ï¼‰
initial_obs = np.concatenate([
    initial_pos,   # pos_agent (2)
    initial_vel,   # vel_agent (2) = 0
    first_goal,    # pos_first_goal (2)
    second_goal    # pos_second_goal (2)
])

# å½’ä¸€åŒ–ï¼ˆä½¿ç”¨æ•°æ®é›†çš„å½’ä¸€åŒ–å‚æ•°ï¼‰
obs_mean = np.array(dataset.obs_mean)
obs_std = np.array(dataset.obs_std)
initial_obs_norm = (initial_obs - obs_mean) / obs_std  # (8,)

# æ„å»ºåºåˆ—ï¼ˆé‡å¤ä¸¤æ¬¡ï¼Œå› ä¸ºåºåˆ—é•¿åº¦=2ï¼‰
# åŒ¹é… IBC çš„ HistoryWrapperï¼štile_first_step_obs=True
obs_seq_norm = np.stack([initial_obs_norm, initial_obs_norm])  # (2, 8)
```

**å¯¹æ¯”ç»“æœï¼šâœ… æ­£ç¡®**
- åˆå§‹é€Ÿåº¦ä¸º 0ï¼ˆåŒ¹é… IBC ç¯å¢ƒé‡ç½®è¡Œä¸ºï¼‰
- ä½¿ç”¨ Z-score å½’ä¸€åŒ–ï¼ˆåŒ¹é…è®­ç»ƒæ—¶çš„å½’ä¸€åŒ–ï¼‰
- åºåˆ—é•¿åº¦ä¸º 2ï¼Œåˆå§‹è§‚æµ‹é‡å¤ä¸¤æ¬¡ï¼ˆåŒ¹é… HistoryWrapper çš„ tile_first_step_obs=Trueï¼‰

### 2.5 PD æ§åˆ¶å™¨å’Œè½¨è¿¹æ¨ç†ï¼ˆç¬¬ 271-275 è¡Œå’Œ 895-909 è¡Œï¼‰

```python
# PD æ§åˆ¶å™¨å‚æ•°ï¼ˆåŒ¹é… IBC Particle ç¯å¢ƒï¼‰
k_p = 10.0
k_v = 5.0
dt = 0.005
repeat_actions = 10  # æ¯ä¸ªåŠ¨ä½œé‡å¤ 10 æ¬¡
```

**å¯¹æ¯”ç»“æœï¼š**
| å‚æ•° | IBC Particle ç¯å¢ƒ | particle_test.py | ç»“æœ |
|------|-------------------|------------------|------|
| k_p | 10.0 | 10.0 | âœ… |
| k_v | 5.0 | 5.0 | âœ… |
| dt | 0.005 | 0.005 | âœ… |
| repeat_actions | 10 | 10 | âœ… |

### 2.6 è§‚æµ‹åºåˆ—æ›´æ–°ï¼ˆç¬¬ 329-339 è¡Œï¼‰

```python
# æ„å»ºæ–°çš„è§‚æµ‹ï¼ˆä¿æŒç›®æ ‡ä¿¡æ¯ï¼Œå½’ä¸€åŒ–ç©ºé—´ï¼‰
new_obs = np.concatenate([
    new_pos,         # pos_agent (2) å½’ä¸€åŒ–
    new_vel,         # vel_agent (2) å½’ä¸€åŒ–
    pos_first_goal,  # pos_first_goal (2) å½’ä¸€åŒ–
    pos_second_goal  # pos_second_goal (2) å½’ä¸€åŒ–
])

# æ›´æ–°è§‚æµ‹åºåˆ—ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
new_obs_tensor = torch.from_numpy(new_obs).float().unsqueeze(0).unsqueeze(0).to(device)
current_obs_seq = torch.cat([current_obs_seq[:, 1:], new_obs_tensor], dim=1)
```

**å¯¹æ¯”ç»“æœï¼šâœ… æ­£ç¡®**
- è§‚æµ‹é¡ºåºï¼špos_agent, vel_agent, pos_first_goal, pos_second_goalï¼ˆåŒ¹é… IBCï¼‰
- ä½¿ç”¨æ»‘åŠ¨çª—å£æ›´æ–°åºåˆ—ï¼ˆåŒ¹é… HistoryWrapper è¡Œä¸ºï¼‰
- ä¿æŒç›®æ ‡ä¸å˜ï¼ˆåŒ¹é… Particle ç¯å¢ƒè¡Œä¸ºï¼‰

---

## 3. æ½œåœ¨é—®é¢˜æ£€æŸ¥

### 3.1 èƒ½é‡ç¬¦å·é—®é¢˜ âš ï¸

**IBC çš„çº¦å®šï¼š**
- ç½‘ç»œè¾“å‡ºï¼š**logits**ï¼ˆåœ¨ TensorFlow ä¸­ï¼Œé«˜ logit = é«˜æ¦‚ç‡ = ä½èƒ½é‡ï¼‰
- èƒ½é‡å®šä¹‰ï¼šE = -logitsï¼ˆå› æ­¤ä½èƒ½é‡ = é«˜ logits = é«˜æ¦‚ç‡ï¼‰

**particle_test.py çš„çº¦å®šï¼š**
- SequenceEBM è¾“å‡ºï¼š**èƒ½é‡å€¼**ï¼ˆä½èƒ½é‡ = é«˜æ¦‚ç‡ï¼‰
- è½¬æ¢ä¸º logitsï¼š`logits = -energies`

**æ£€æŸ¥ SequenceEBM çš„è¾“å‡ºå«ä¹‰ï¼š**

æŸ¥çœ‹ `core/models.py` ä¸­ SequenceEBM çš„å®šä¹‰ï¼Œç¡®è®¤è¾“å‡ºæ˜¯å¦ä¸ºèƒ½é‡å€¼ã€‚

**ç»“è®ºï¼š**
å¦‚æœ SequenceEBM çš„è¾“å‡ºæ˜¯èƒ½é‡å€¼ï¼ˆä½èƒ½é‡ = å¥½åŠ¨ä½œï¼‰ï¼Œåˆ™å½“å‰å®ç°æ­£ç¡®ã€‚
å¦‚æœ SequenceEBM çš„è¾“å‡ºæ˜¯ logitsï¼ˆé«˜ logits = å¥½åŠ¨ä½œï¼‰ï¼Œåˆ™åº”è¯¥å»æ‰è´Ÿå·ã€‚

**éœ€è¦éªŒè¯ï¼š** SequenceEBM çš„è¾“å‡ºå«ä¹‰ä¸è®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°å®šä¹‰ä¸€è‡´ã€‚

### 3.2 å½’ä¸€åŒ–ç©ºé—´çš„ä¸€è‡´æ€§ âœ…

**è®­ç»ƒæ—¶ï¼š**
- è§‚æµ‹ï¼šZ-score å½’ä¸€åŒ–
- åŠ¨ä½œï¼šMin-Max å½’ä¸€åŒ–åˆ° [-1, 1]

**æ¨ç†æ—¶ï¼š**
- è§‚æµ‹ï¼šä½¿ç”¨ç›¸åŒçš„ Z-score å½’ä¸€åŒ–å‚æ•° âœ…
- åŠ¨ä½œï¼šåœ¨ [-1, 1] ç©ºé—´é‡‡æ · âœ…
- PD æ§åˆ¶å™¨ï¼šåœ¨å½’ä¸€åŒ–ç©ºé—´è¿è¡Œ âœ…

**ç»“è®ºï¼šå½’ä¸€åŒ–ç©ºé—´ä½¿ç”¨ä¸€è‡´**

### 3.3 åˆå§‹åŒ–ç­–ç•¥ âœ…

**IBCï¼ˆ`ibc_policy.py` ç¬¬ 263-265 è¡Œï¼‰ï¼š**
```python
action_samples = tensor_spec.sample_spec_nest(
    self._action_sampling_spec,
    outer_dims=(batch_size * self._num_action_samples,)
)
```
- ä½¿ç”¨ spec çš„èŒƒå›´è¿›è¡Œå‡åŒ€é‡‡æ ·

**particle_test.pyï¼ˆç¬¬ 439-443 è¡Œï¼‰ï¼š**
```python
init_negatives = torch.rand(
    B, num_counter_examples, action_dim,
    device=device
) * 2.0 - 1.0  # èŒƒå›´ [-1, 1]
```
- åœ¨ [-1, 1] èŒƒå›´å‡åŒ€é‡‡æ ·

**ç»“è®ºï¼šåˆå§‹åŒ–ç­–ç•¥ä¸€è‡´** âœ…

---

## 4. æ€»ç»“

### âœ… **æ¨ç†é…ç½®å®Œå…¨æ­£ç¡®çš„éƒ¨åˆ†**

| é…ç½®é¡¹ | IBC å®˜æ–¹ | particle_test.py | ç»“æœ |
|--------|----------|------------------|------|
| **Langevin é‡‡æ ·å™¨** |  |  |  |
| - åˆå§‹æ­¥é•¿ | 0.1 | 0.1 | âœ… |
| - è¿­ä»£æ¬¡æ•° | 100 | 100 | âœ… |
| - æœ€ç»ˆæ­¥é•¿ | 1e-5 | 1e-5 | âœ… |
| - æ­¥é•¿è¡°å‡å¹‚æ¬¡ | 2.0 | 2.0 | âœ… |
| - å™ªå£°å°ºåº¦ | 1.0 | 1.0 | âœ… |
| **é‡‡æ ·é…ç½®** |  |  |  |
| - å€™é€‰åŠ¨ä½œæ•°é‡ | 512 | 512 | âœ… |
| - æ¸©åº¦å‚æ•° | 1.0 | 1.0 | âœ… |
| - åˆå§‹åŒ–èŒƒå›´ | action_spec | [-1, 1] | âœ… |
| **åŠ¨ä½œé€‰æ‹©** |  |  |  |
| - é€‰æ‹©ç­–ç•¥ | GreedyPolicy (argmax) | probs.argmax() | âœ… |
| - æ¦‚ç‡è®¡ç®— | softmax(logits/T) | softmax(-E/T) | âœ… |
| **è§‚æµ‹å¤„ç†** |  |  |  |
| - åˆå§‹é€Ÿåº¦ | 0 | 0 | âœ… |
| - è§‚æµ‹é¡ºåº | pos, vel, goal1, goal2 | ç›¸åŒ | âœ… |
| - å½’ä¸€åŒ–æ–¹å¼ | Z-score | Z-score | âœ… |
| - åºåˆ—é•¿åº¦ | 2 | 2 | âœ… |
| - åºåˆ—åˆå§‹åŒ– | tile_first_step_obs | é‡å¤ä¸¤æ¬¡ | âœ… |
| **PD æ§åˆ¶å™¨** |  |  |  |
| - k_p | 10.0 | 10.0 | âœ… |
| - k_v | 5.0 | 5.0 | âœ… |
| - dt | 0.005 | 0.005 | âœ… |
| - repeat_actions | 10 | 10 | âœ… |

### âš ï¸ **éœ€è¦ç¡®è®¤çš„éƒ¨åˆ†**

1. **èƒ½é‡ç¬¦å·çº¦å®š**ï¼š
   - ç¡®è®¤ SequenceEBM çš„è¾“å‡ºæ˜¯èƒ½é‡å€¼è¿˜æ˜¯ logits
   - å¦‚æœæ˜¯èƒ½é‡å€¼ï¼ˆä½èƒ½é‡ = å¥½ï¼‰ï¼Œå½“å‰çš„ `logits = -energies` æ˜¯æ­£ç¡®çš„
   - å¦‚æœæ˜¯ logitsï¼ˆé«˜å€¼ = å¥½ï¼‰ï¼Œåº”è¯¥å»æ‰è´Ÿå·

2. **è®­ç»ƒä¸æ¨ç†ä¸€è‡´æ€§**ï¼š
   - ç¡®è®¤è®­ç»ƒæ—¶ InfoNCE æŸå¤±çš„å®šä¹‰ä¸æ¨ç†æ—¶çš„èƒ½é‡è§£é‡Šä¸€è‡´
   - è®­ç»ƒæ—¶ï¼š`softmax(-energies / temperature)`ï¼Œæ­£æ ·æœ¬èƒ½é‡åº”è¯¥è¾ƒä½
   - æ¨ç†æ—¶ï¼š`softmax(-energies / temperature)`ï¼Œé€‰æ‹©èƒ½é‡æœ€ä½çš„åŠ¨ä½œ

### ğŸ“‹ **å»ºè®®**

1. **éªŒè¯èƒ½é‡ç¬¦å·çº¦å®š**ï¼š
   æ£€æŸ¥ `particle_train.py` ç¬¬ 163-194 è¡Œçš„ `compute_info_nce_loss` å‡½æ•°ï¼š
   ```python
   # å¦‚æœè¿™é‡Œä½¿ç”¨ -energiesï¼Œè¯´æ˜ç½‘ç»œè¾“å‡ºæ˜¯èƒ½é‡å€¼
   probs = F.softmax(-energies / temperature, dim=-1)
   ```
   
   ä¸ `particle_test.py` ç¬¬ 194 è¡Œå¯¹æ¯”ï¼š
   ```python
   logits = -energies / temperature  # åº”è¯¥ä¿æŒä¸€è‡´
   ```

2. **æ·»åŠ è°ƒè¯•è¾“å‡º**ï¼ˆç¬¬ä¸€æ­¥æ¨ç†ï¼‰ï¼š
   ```python
   if step == 0:
       print(f"å€™é€‰åŠ¨ä½œèƒ½é‡èŒƒå›´: [{energies.min():.4f}, {energies.max():.4f}]")
       print(f"é€‰æ‹©åŠ¨ä½œçš„èƒ½é‡: {selected_energy:.4f}")
       print(f"é¢„æµ‹åŠ¨ä½œ: {next_action}")
   ```

---

## 5. ç»“è®º

**æ¨ç†é…ç½®ä¸ IBC å®˜æ–¹å®Œå…¨å¯¹é½ï¼Œæ‰€æœ‰å…³é”®å‚æ•°å’Œæµç¨‹éƒ½æ­£ç¡®å®ç°ã€‚**

å”¯ä¸€éœ€è¦ç¡®è®¤çš„æ˜¯èƒ½é‡ç¬¦å·çº¦å®šçš„ä¸€è‡´æ€§ï¼Œä½†ä»ä»£ç ç»“æ„çœ‹ï¼Œè®­ç»ƒå’Œæ¨ç†ä½¿ç”¨äº†ç›¸åŒçš„ç¬¦å·çº¦å®šï¼ˆéƒ½ä½¿ç”¨ `-energies`ï¼‰ï¼Œå› æ­¤åº”è¯¥æ˜¯æ­£ç¡®çš„ã€‚

**å…³é”®æ­£ç¡®ç‚¹ï¼š**
1. âœ… Langevin é‡‡æ ·å™¨é…ç½®å®Œå…¨åŒ¹é…
2. âœ… åŠ¨ä½œé€‰æ‹©ç­–ç•¥ï¼ˆargmaxæ¦‚ç‡ï¼‰åŒ¹é… GreedyPolicy
3. âœ… è§‚æµ‹åºåˆ—æ„å»ºå’Œå½’ä¸€åŒ–æ­£ç¡®
4. âœ… PD æ§åˆ¶å™¨å‚æ•°åŒ¹é… Particle ç¯å¢ƒ
5. âœ… åˆå§‹é€Ÿåº¦ä¸º 0ï¼ŒåŒ¹é…ç¯å¢ƒé‡ç½®è¡Œä¸º
6. âœ… æ»‘åŠ¨çª—å£æ›´æ–°è§‚æµ‹åºåˆ—

